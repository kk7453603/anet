# Настройка QUIC-транспорта

Секция `[quic_transport]` управляет поведением протокола QUIC на транспортном уровне. Корректная настройка этих параметров важна для достижения оптимальной производительности VPN-соединения.

## Алгоритм контроля перегрузки

Параметр `algorithm` определяет стратегию адаптации скорости передачи данных при изменении состояния сети.

### BBR (рекомендуемый)

```toml
[quic_transport]
algorithm = "bbr"
```

Алгоритм от Google. Определяет реальную пропускную способность канала и RTT, поддерживая высокую скорость даже при наличии потерь пакетов. Рекомендуется для:

- Нестабильных каналов (мобильные сети, Wi-Fi)
- Соединений с высоким RTT
- Серверов, обслуживающих клиентов с различными характеристиками каналов

### CUBIC

```toml
[quic_transport]
algorithm = "cubic"
```

Традиционный алгоритм. Более чувствителен к потерям пакетов и может значительно снижать скорость при нестабильном соединении. Допустим для стабильных каналов с низкой потерей пакетов.

## Параметры канала

### RTT (Round-Trip Time)

```toml
[quic_transport]
expected_rtt_ms = 80
```

Начальная оценка времени кругового пути в миллисекундах. Используется протоколом QUIC для инициализации таймеров и алгоритма контроля перегрузки. Укажите значение, близкое к среднему пингу до VPN-сервера.

Для определения RTT:

```bash
ping vpn.example.com
```

### Пропускная способность

```toml
[quic_transport]
bandwidth_down_mbps = 50    # скорость загрузки (сервер → клиент), Мбит/с
bandwidth_up_mbps = 30      # скорость отдачи (клиент → сервер), Мбит/с
```

Оценки пропускной способности канала, используемые для автоматического расчёта размеров буферов. Укажите значения, соответствующие реальным характеристикам вашего интернет-соединения.

На сервере эти параметры отражают пропускную способность серверного канала:

```toml
# Серверная конфигурация
[quic_transport]
bandwidth_down_mbps = 1000   # исходящая (клиенту)
bandwidth_up_mbps = 1000     # входящая (от клиента)
```

## Размеры буферов (Flow Control Windows)

По умолчанию буферы рассчитываются автоматически на основе Bandwidth-Delay Product (BDP):

```
BDP = (bandwidth_mbps * 125000) * (rtt_ms / 1000)
window = max(BDP * 2.5, 1048576)    # минимум 1 МиБ
```

Для большинства сценариев автоматический расчёт является оптимальным. Ручная настройка допустима при наличии специфических требований.

### Ручная настройка

```toml
[quic_transport]
# Окно приёма для отдельного QUIC-потока (байты)
# stream_receive_window = 262144

# Общее окно приёма для всего соединения (байты)
# receive_window = 1048576

# Окно отправки (байты)
# send_window = 1048576
```

> Если ручные значения не указаны, используется автоматический расчёт.

## Дополнительные параметры

### GSO (Generic Segmentation Offload)

```toml
[quic_transport]
enable_gso = true
```

Перекладывает задачу сегментации пакетов на сетевую карту, снижая нагрузку на CPU. Рекомендуется оставить включённым. Особенно важно на сервере при обслуживании множества одновременных соединений.

### Таймаут неактивности

```toml
[quic_transport]
idle_timeout_seconds = 21600    # 6 часов
```

Время в секундах, после которого неактивное соединение считается разорванным. Большое значение (несколько часов) повышает стабильность на длительных сессиях.

> Рекомендуется устанавливать одинаковое значение на клиенте и сервере.

### MTU

```toml
[quic_transport]
max_mtu = 1500
```

Верхний предел для механизма Path MTU Discovery. В подавляющем большинстве случаев значение 1500 (стандартный Ethernet MTU) является оптимальным. Изменяйте только при наличии уверенности в поддержке jumbo-кадров в вашей сети.

## Примеры конфигураций

### Быстрый стабильный канал (оптоволокно, VPS в одном регионе)

```toml
[quic_transport]
algorithm = "bbr"
expected_rtt_ms = 20
bandwidth_down_mbps = 200
bandwidth_up_mbps = 100
enable_gso = true
idle_timeout_seconds = 21600
max_mtu = 1500
```

### Мобильная сеть (4G/5G)

```toml
[quic_transport]
algorithm = "bbr"
expected_rtt_ms = 80
bandwidth_down_mbps = 30
bandwidth_up_mbps = 10
enable_gso = true
idle_timeout_seconds = 3600
max_mtu = 1500
```

### Высокий RTT (удалённый сервер, спутниковый канал)

```toml
[quic_transport]
algorithm = "bbr"
expected_rtt_ms = 200
bandwidth_down_mbps = 50
bandwidth_up_mbps = 20
enable_gso = true
idle_timeout_seconds = 21600
max_mtu = 1500
```

### Серверная конфигурация (выделенный сервер 1 Гбит/с)

```toml
[quic_transport]
algorithm = "bbr"
expected_rtt_ms = 60
bandwidth_down_mbps = 1000
bandwidth_up_mbps = 1000
enable_gso = true
idle_timeout_seconds = 21600
max_mtu = 1500
```

## Справочник параметров

| Параметр | Тип | По умолчанию | Описание |
| --- | --- | --- | --- |
| `algorithm` | String | `"bbr"` | Алгоритм контроля перегрузки: `"bbr"` или `"cubic"` |
| `expected_rtt_ms` | u32 | `60` | Начальная оценка RTT (мс) |
| `bandwidth_down_mbps` | u32 | `200` | Пропускная способность загрузки (Мбит/с) |
| `bandwidth_up_mbps` | u32 | `100` | Пропускная способность отдачи (Мбит/с) |
| `stream_receive_window` | u64 (опц.) | Авто | Окно приёма потока (байты) |
| `receive_window` | u64 (опц.) | Авто | Общее окно приёма (байты) |
| `send_window` | u64 (опц.) | Авто | Окно отправки (байты) |
| `enable_gso` | bool | `true` | Включить GSO |
| `idle_timeout_seconds` | u64 (опц.) | `3600` | Таймаут неактивности (секунды) |
| `max_mtu` | u16 | `1500` | Верхний предел MTU |
